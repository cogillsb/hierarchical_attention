# Stacked duel bidirectional LSTM layers
This is an older model we built to create a semi-interpretable deep net for entry systems. It consisted of two attention networks sitting on top of the LSTMs, and by
pulling the weights from the network, we were able to glean which entries were important and specifically what inside said entries was important.

This is older work that resulted in the following publication which had a modified version of the model:
https://pubmed.ncbi.nlm.nih.gov/37468526/
